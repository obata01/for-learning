---
title: "Untitled"
author: "obata.yoshimasa"
date: "2021/9/23"
output: slidy_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## 一般化線形モデル

「ばらつきは何でもかんでも正規分布」と考えるのはおかしいだろう ------ というのが一般化線形モデル

ex) 目的変数がポアソン分布に従うと仮定したポアソン回帰


## 3.1 例題：個体ごとに平均種子数が異なる場合

標本：架空植物100個体

 - 種子数 $y_i$ (目的変数)
 - 属性（誤差（個体差）を与える観測データ）
   - 体サイズ $x_i$
   - 施肥処理の有無 $f_i$ (f : Factor)
     - 処理C：全個体中50個体 $(i \in {1, 2, \cdots, 50})$ は何も処理をしていない群
     - 処理T：残りの50個体 $(i \in {51, 52, \cdots, 100})$ は処理（肥料）を加えた群

→ $x_i$ と $f_i$ が種子数 $y_i$ にどう影響しているのか知りたい.


## 3.2 観測されたデータの概要を調べる

### データ読み込み
CSVファイルを読み込んでデータフレームとして変数dに格納

```{r}
# f列をfactorとするため, 引数に"stringsAsFactors = TRUE"を追加
d <- read.csv("../data/data3a.csv", stringsAsFactors = TRUE)
# print(d)
head(d, 5)
```


デフォルトがFALSEになっているため注意<br>

-> https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/read.table

```{r}
getOption("stringsAsFactors") 
```


### 概要の確認

#### 列ごとの確認

```{r}
# x列・y列のみの表示
d$x
d$y
```

```{r}
# f列(因子：factor)のみの表示
# CSVファイルを読み込んだ時、文字列を含む列はfactorに変換される.
d$f
```

#### class()を用いてデータオブジェクトが属するクラスを表示

```{r}
class(d)
# yは整数のみのため"integer"
class(d$y)
# xは実数も含むため"numeric"
class(d$x)
# fは文字列を含むため"factor"
class(d$f)
```

#### 基本統計量

```{r}
summary(d)
```


## 3.3 統計モデリングの前にデータを図示する

### 散布図

```{r}
plot(d$x, d$y, pch = c(21, 19)[d$f])
legend("topleft", legend = c("C", "T"), pch = c(21, 19))
```

### 箱ひげ図

```{r}
plot(d$f, d$y)
legend("topleft", legend = c("C", "T"), pch = c(21, 19))
```

## 3.4.1 線形予測子と対数リンク関数

ポアソン回帰の説明はこちらが詳しい
 -> https://www.slideshare.net/logics-of-blue/2-3glm

#### ポアソン分布
第2章同様、ある個体 $i$ の種子数が $y_i$ である確率 $p(y_i|\lambda_i)$ は, ポアソン分布に従うと仮定する.

$$
  p(y_i | \lambda_i) = \frac{\lambda_i^{y_i} exp(-\lambda_i)}{y_i !}
$$

#### 線形予測子とリンク関数

個体ごとに異なる平均種子数 $\lambda_i$ を説明変数 $x_i$ の関数として定義する.

ポアソン分布は$\lambda$によって決まるため、$\lambda$を推定する予測式を立てる必要がある.

-> つまり、ある個体の体サイズ $x_i$ に応じて $\lambda$ が異なる. <br>
-> つまり、例えばサイズが8のとき種子数は平均6を前後にばらつき、<br>
　　サイズが10のときは種子数は平均10を前後にばらつく･･･といったようになるが, その誤差はポアソン分布に従う.

$$
  \lambda_i = exp(\beta_1 + \beta_2 x_i) \\
  \Leftrightarrow \ log \lambda_i = \beta_1 + \beta_2 x_i \ \ \cdots ①
$$

上記式はポアソン分布・二項分布の*正準リンク関数*となっている.<br>
※ロジスティック回帰の正準リンク関数はロジットリンク関数

①式の左辺と右辺はそれぞれ次のように呼ぶ.
- 左辺：(対数)リンク関数
- 右辺：線形予測子

ポアソン回帰のGLMで対数リンク関数が用いられる理由
- $\lambda = exp(線形予測子) \ge 0$ であり, 常に非負になる


```{r}
lambda_a <- function(x) {
  β_1 <- -1
  β_2 <- 0.4
  return(exp(β_1 + β_2*x))
}

lambda_b <- function(x) {
  β_1 <- -2
  β_2 <- -0.8
  return(exp(β_1 + β_2*x))
}

plot(lambda_a, -5, 5, ylab="λ")
par(new=T)
plot(lambda_b, -5, 5, ylab="", lty=2)
```

## 3.4.2 あてはめとあてはまりの良さ

ポアソン回帰は、対数尤度$logL$ が最大になるパラメータ $\hat{\beta_1}, \hat{\beta_2}$ を決めること.

$$
  \log L(\beta_1, \beta_2) = \sum_{i} \log \frac{\lambda_i^{y_i} exp(-\lambda_i)}{y_i !}
$$


Rでは次のように実行

```{r}
fit <- glm(y ~ x, data = d, family = poisson(link = "log"))
fit
summary(fit)
```